title: 阿里全球调度算法大赛 GSAC 2018 总结 - 2
date: 2018-10-05
category: cloud
tags:
---

这是[阿里全球调度算法大赛 GSAC 2018](https://tianchi.aliyun.com/competition/information.htm?raceId=231663)总结的算法部分。

<!--more-->

---

{% math %}
\begin{aligned}
\end{aligned}
{% endmath %}

# 2. 搜索
这一节讨论在线应用的部署优化算法。前面提到，Top 6 的队伍中有 5 支队伍都用了<a href="https://en.wikipedia.org/wiki/Local_search_(optimization)" target="_blank">局部搜索（Local search）</a>。
我们可以把可行的部署表示为一个高维空间，因为每个实例（inst）只能部署在某一台机器上，对 $$N$$ 个实例，$$M$$ 台机器，每个实例可能部署在 $$M$$ 台机器的任一台上， 一个部署方案（解）就是 $$M^N$$ 这样一个高维空间中的点。考虑到资源约束和干扰约束，空间中有的点是非法解。合法解的成本分数是不同的。所谓 **搜索**，就是在这个高维中间找到最优解的那个点。
**局部（Local）** 的说法有点误导。这里是指对 **初始解** 做一点变动，从而转到另一个点。所以，我们首先要有一个 **初始解**，可以是自己的装箱算法得到的，也可以直接用比赛数据的初态。对初始解稍作变动，新得到的解称为 **邻域（Neighbor）**。**变动** 不必符合 **（欧式）距离** 的定义，实际上我们并不关心 **距离** 的长度，只是表示邻域与初始解的差异不大，比较容易得到。
对不同的问题，邻域的定义是不同的。比如旅行商问题（TSP），可以是交换初始路线中 **某两个城市的顺序（2-opt）**。
对于比赛的部署问题，我们可以定义邻域为实施了下面变动的结果，
+ 迁移（Move / Shift）：移动一个实例到另一台机器
+ 交换（Swap）：对不同机器上的两个实例，交换它们所在的机器
+ 1 vs N 的交换：对比较大的实例，可以一次性与另一台机器上的N个小的实例交换

实际上（1 vs 1 和 1 vs N 的）交换是多步迁移的组合，所有也可以只用迁移。
理想情况下，经过足够多次的迁移，我们是可以达到最优解的。显然，搜索空间是相当巨大的，但对这次比赛，局部搜索的效果相当好。

## 2.1 随机搜索
随机选择一个实例（也可以先随机选一台机器 $$m_{from}$$ ，再随机选一个 $$m_{from}$$ 上部署的实例），之后随机选择一台目标机器（$$m_{to}$$）。如果满足约束，而且部署到 $$m_{to}$$ 后，总成本分数降低了，那么就确认实施这次迁移。
对上面的动作不断迭代，因为每次都会把总分数降低一点，所以执行足够长的时间后，我们期望可以接近，甚至达到最优解。

### 结束条件
可以想到，每个有效迁移（满足约束，而且能减少成本分数）能减少的分数是不同的。搜索的初期，可能比较容易碰到显著减少分数的迁移，到后期，搜索到有效迁移的概率会越来越低。如果把每步迁移后的分数打印出来，效果就是程序刚启动时，屏幕快速刷新，分数很快下降，但逐渐输出越来越慢，分数下降也越来越少。
因为随机性，可能有的组合被选中多次（当然，机器的状态已经变了，所以是不同的迁移），还有可能同一个实例被迁移到多个不同的机器上。为了减少这些低效的迁移，可以限制每个有效迁移的分数差值，将阈值（$$Th$$）从 0 改为一个适当的负数，只接受比较显著的迁移。随着不断搜索，应适当减小阈值 $$Th$$ 的绝对值。

当搜索的进展到一定程度，对解的改进越来越小，就可以结束了；也可以设置定时器，或者最大迭代次数，或者搜索失败次数。我们的做法是既设置定时器，还响应终端的 `Ctrl+C` 按键，可以手动控制搜索进度。显然每次搜索结束后要把结果保存下来。我们保存的是集群的终态，每行的格式为 
`机器Id，[该机器上部署实例Id的列表]` 
下次搜索可以读入这个文件，继续搜索。

### 并发，死锁
我们可以在随机搜索的基础上继续改进。

首先，注意到每个迁移只涉及两台机器：实例最初所在的机器（$$m_{from}$$），和目标机器（$$m_{to}$$）。迁移只影响这两台机器的成本分数，只要迁移后两台机器的分数之和减小了，就会降低总的分数 。
我们可以通过 **并发** 来加速搜索的过程。需要对迁移涉及的 $$m_{from}$$ 和 $$m_{to}$$ 两台机器加锁。这是一个典型的可能发生 **死锁** 的情况。解决的方案也很简单，只要保持 **确定的加锁顺序** 即可。我们的做法是，总是对 $$m_{from}$$ 和 $$m_{to}$$ 这两台机器中 **Id 较小** 的机器（记为 $$m_1$$）先加锁，如果无法获得锁，就直接取消这步迁移（因为搜索本身是随机的，又在不断进行，跳过一步没有太大影响）； $$m_1$$ 获得锁之后， $$m_2$$ 接着加锁，如果不能获得锁，则等待。对 $$m_2$$ ，肯定还会发生 **锁争用** 的情况，但不会因为两阶段加锁导致 **死锁**。
感兴趣的同学可以分析一下另一个线程尝试对（$$m_1,m_x$$），（$$m_2,m_x$$），（$$m_1,m_2$$）这三组有关机器组合加锁时线程间的交互，其中 $$m_x$$ 是不同于 $$m_1, m_2$$ 的机器。

### 实例/机器的选择
直觉上，从分数较高的机器上选择要迁移的实例，比随机选择 **可能更有效**。
也可以从实例本身的特性考虑，比如资源使用量较大，或者 CPU /内存曲线波动较大，或者干扰规则较多的实例被迁移的概率可以较大。
> 注意，一般多个实例属于同一应用（App），它们的资源特性是相同的。有的情况按应用来考虑，可以避免重复计算（实例共 68k 多个，应用则 9.8k 多个）。

对于迁移的目标机器，可能分数较低的机器是更好的选择；当然也可以比较剩余可用资源；大型机器比小型机器也更适合作为迁移目标。
另一个思路，每次不只选择一台目标机器，而是选择多台，从中选择分数降低最多的机器作为目标，甚至从集群所有机器中选择，这就相当于最佳适合（Best Fit）装箱算法了。
原则上说，一步选择多台机器与执行多次随机迁移是相似的，但固定了待迁移的实例，因此可能效果更好些。

### 均衡机器
还有一种思路，不是迁移实例，而是均衡机器。我们把上面选择实例-机器的策略记为 $$I+M$$，这里均衡机器的策略记为 $$M+M$$。
首先，随机选择两台机器 $$m_1,m_2$$，然后将 $$m_1,m_2$$ 的所有实例（总个数记为 $$N_{m1}+N_{m2}$$，平均约为 20）重新在这两台机器之间部署，使两台机器的分数之和最小。
两台机器可能的实例部署方案有 $$2^{N_{m1}+N_{m2}}$$ 种（有的方案会违反约束，是不可行的；如果 $$m_1,m_2$$ 是同类型的机器，考虑对称性，总数应减少一半，不过只是指数减 1）。
显然难以通过枚举所有方案找到最优解。可以按下面的方法获得近似解：
+ 同样可以随机选择一个实例，待迁移目标是另一台机器。**6th - 地球漫步** 就是采用的这种做法，并限制迭代次数
+ **3rd - rivulet队** 的做法是从两台空机器开始，依次放入实例，$$inst_0$$ 有 2 个选择，下一步放 $$inst_1$$ 同样有 2 个选择，总的方案是 $$2^2=4$$ 个了，可以表示为一个满二叉树，最低层有 $$2^2=4$$ 个叶子。每放一个实例，二叉树长一层，放完所有实例，最底一层就是 $$2^{N_{m1}+N_{m2}}$$ 种部署方案。因为无法保存整棵数，他们只保留每层中成本分数最低的 10 个叶子，不可行的以及成本分数较大的方案被剪掉了。
假设机器 $$m_1$$ 的分数小于 $$m_2$$ 的。将实例部署到 $$m_1$$ 后，其分数 **不一定仍小于** 将实例部署到 $$m_2$$ 的分数，因为 $$m_2$$ 的可用资源可能与实例的 CPU 使用曲线更匹配。由于不保证单调性，所以剪枝是近似的。
+ **1st - 我就看看队** 也是随机搜索，除了 Move，还使用了 Swap 。

同样，均衡机器的策略也可以改进。可以分别选择一台分数大的机器，一台分数小的，作为一组。**6th - 地球漫步** 就是这种做法。他还巧妙地利用分组避免了并发加锁。
他的算法中，一轮并发开始之前，先将机器按分数从大到小排序，依次填入一个数组的奇数位置，然后将机器按分数从小到大排序，依次填入数组的偶数位，这样相邻两个机器的分数一大一小，作为一组传给一个 goroutine 执行均衡（他使用的 go 语言）。因为每个 goroutine 的机器组合没有交集，也就不必对机器加锁了。当然，这样需要一轮一轮地执行，如果对机器加锁，则不必明显分轮次执行了。随机情况下，争用锁的情况可能不太严重。

## 2.2 退火
实际上 [模拟退火（Simulated annealing，SA）](https://en.wikipedia.org/wiki/Simulated_annealing)并不是一个完整的算法，它需要配合局部搜索，作用是动态调整搜索策略。当温度较高时，以较大的概率接受较差的解，从而增加搜索的多样性；温度较低时，则降低接受较差解的概率，更专注搜索。
**5th - yxgy** 和 **1st - 我就看看队** 都使用了 SA。
+ **5th - yxgy** 使用的是标准的 SA，局部搜索采用了 Move 和 Swap ，选择策略是 $$I+M$$。由于复赛限制不超过三轮迁移，他在每轮的策略不同：第一轮期望将实例均匀分布，在所有机器中随机选择；第二，三轮尝试固实机器，把负载较轻，仅有少数实例的机器腾空，将其上的实例迁移到其它机器上
+ **1st - 我就看看队** 的选择策略是 $$M+M$$ 均衡两台机器，两台机器是随机选择的。只接受能减少分数的动作，不考虑接受较差的解，所以退火温度并没有起作用，实际就是 **随机搜索**。

## 2.3 禁忌
[禁忌（Tabu）搜索](https://en.wikipedia.org/wiki/Tabu_search)也是一种配合局部搜索的算法。它可以记住前面若干步的搜索动作，避免重复搜索。
我们采用了禁忌搜索，实例和机器的选择策略是 $$I+M$$。随机选择一台机器 $$m_{from}$$，将其实例按 CPU 使用量平均值从大到小排序，选择第一个满足约束，且降低了分数的实例；选择目标机器 $$m_{to}$$ 时，为大型机器分配的概率较大。选择 $$L$$ 个组合后，只实施降低分数最显著的那步迁移。
看起来我们没必要搞得这么复杂。禁忌或者退火并不是搜索的关键，执行尽可能多的迭代，也就是 **并发**，以及实例和机器的 **选择策略** 才是重点。

## 2.4 其它
比赛时，微信群里有人提到过粒子群、蚁群，遗传算法和强化学习等启发式算法。这些算法由于不容易编码部署方案，或者不容易处理干扰约束，可能不太合适。另外，跟禁忌或退火类似，这些算法可能作用没有那么大。

## 2.5 机器数/下界
减少使用的机器数量是优化的一个目标。使用了不同机器总数，能达到的最低总成本分数是不同的。
使用的机器总数有一个下限，比下限更少的机器数量就无法提供足够的资源来部署所有实例了。
从下限开始逐渐增加机器数量，可以预期总成本分数会随之降低；当达到了全局最优部署方案对应的机器数量之后，再增加机器，这时成本分数分段特性的影响就显示出来了 —— 只要有实例部署的机器，其成本分数最少也是 1 —— 总成本分数又开始增加了。

理想情况是搜索算法可以 **自动收敛到最优的机器数量**。上面提到的搜索动作中，只有迁移才可能清空一台机器的实例，减少使用机器的数量；均衡机器的策略不会减少机器数量。不过都可以直接限制使用的机器总数，尝试不同的机器总数，搜索全局最优解。

初赛结束后，**1st - 我就看看队**的月光鸣下介绍了 [估算分数下界的方法](https://tianchi.aliyun.com/forum/new_articleDetail.html?raceId=231663&postsId=6749)。我在后面贴了一段 Python 实现，这里稍微重构一下：

> 注意，下面是初赛的成本分数公式，复赛的公式中使用了实例个数，可以用常量近似
> **我就看看队** 的估算代码有所差别，可参考 https://gitlab.com/thyrix/tianchi_scheduling_2018/blob/parallel/read.cpp?L=363#L363 

```python
# coding=utf-8

# 参考: https://tianchi.aliyun.com/forum/new_articleDetail.html?postsId=6749#pages=2

from math import exp

T = 98             # 约每 15 min一个数据点, 98 个点共24.5 h
Cap_large = 92     # Cap 指 Cpu Capacity, 单位是核数; large, small 指机器容量大小
Cap_small = 32
m_cnt_large = 3000 # m 指 Machine, 初赛数据集 B 共 3000 台大型机器

# Cpu 数组是分时合计的所有实例的 Cpu 使用量，并舍入为整数（舍入是不必要的，只是为了排版整齐）
Cpu = [188828, 186020, 184437, 179184, 173859, 170777, 171091,
       171391, 172762, 171062, 168794, 161486, 154872, 147752,
       145651, 141275, 138090, 135057, 133550, 130775, 130199,
       132061, 133945, 134582, 136533, 138786, 141852, 142290,
       144728, 146617, 149767, 151421, 156606, 162025, 168495,
       172771, 177946, 182382, 187403, 190954, 195316, 199537,
       202072, 202899, 204603, 205017, 204517, 201572, 198979,
       194286, 191600, 187234, 187484, 186463, 189383, 191000,
       193782, 194522, 197478, 196029, 195770, 195136, 196245,
       194962, 194931, 193154, 193079, 189648, 186942, 183407,
       180333, 175104, 171876, 167541, 165578, 163567, 162540,
       162537, 165319, 165752, 166385, 166886, 167191, 164786,
       163373, 161429, 160551, 158307, 154784, 150071, 146009,
       141665, 137909, 133101, 129825, 125324, 122218, 117043]


def score(util):
    return 1+10*(exp(max(util - 0.5, 0.0)) - 1)


def total_score(m_cnt, util_small):
    m_cnt_small = m_cnt - m_cnt_large
    score_small = score(util_small) * m_cnt_small

    score_large = 0.0
    for i in range(T):
        util_large = (Cpu[i] - m_cnt_small * Cap_small * util_small) / (m_cnt_large * Cap_large)
        score_large += score(util_large) * m_cnt_large

    return score_small + score_large / T


def search(span):
    for m_cnt in span:
        min_score = 1e9
        for u in range(40, 80):    
            util_small = u / 100.0  # 从 0.4 到 0.8，步长 0.01
            _score = total_score(m_cnt, util_small)

            if min_score > _score:
                min_score = _score   # 最小值对应的 util_small 总是 0.5

        print("%d:%.2f" % (m_cnt, min_score))


if __name__ == '__main__':
    search(range(4000, 6000, 50))  # 粗搜，步长 50
    print("==========\n")
    search(range(4789, 4828))      # 细搜，步长  1
```

上面代码总是使用全部 3000 台大型机器（对初赛数据集 B ，`m_cnt_large = 3000`）。逐步增加机器总数 `m_cnt`，也就是增加小型机器的数量 `m_cnt_small = m_cnt - 3000`。`Cpu` 列表是合计所有实例的 CPU 分时使用量。
因为是估算，一些简化是可以接受的。不同时刻的 CPU 是有关联的，这里忽略关联，并假设小型机器所有时刻的 CPU 利用率相同，如果资源比较紧张，需要使用超过 50% 以上利用率的 CPU，只考虑大型机器，所以不同时刻大型机器的 CPU 利用率不同，与机器数相关。
最终 4800 台机器左右，总分数最小。可以在这个值附近尝试搜索最优部署。

# 3. 迁移
复赛对迁移限制了轮次，而且是先新建后删除的迁移机制。
一种方案是每步搜索都按迁移机制的要求，不从旧机器上释放已迁移实例占用的资源，干扰约束也要假设实例仍存在；但是，计算机器的成本分数 **不应考虑实例未释放的资源**。因为每步都是满足迁移限制的，直接输出迁移动作就可以了。**5th - yxgy** 使用了这种方案。我们也是这种方案。另外，为了减少队代码的改动，我们用了偷懒的做法，克隆了一个 **影子部署方案**，与当前方案同步执行迁移动作，当前方案会释放实例在旧机器上的资源，用来计算成本，影子方案则不释放，用来检查约束。我们是手工决定何时结束每轮的。用这种方案生成的迁移动作比较少，提交文件只有几百 KB 。

另一种方案，执行局部搜索时不考虑迁移的限制，搜索到优化的终态后，与数据集的初态比较，生成迁移动作，这时再考虑迁移的限制。
为了减少迁移动作，需要尽量 “对齐” 初态和终态的机器，这相当于[二分图](https://en.wikipedia.org/wiki/Bipartite_graph)最优匹配问题。所谓 “对齐” ，如果是从初态开始通过局部搜索得到的终态，那么搜索过程中可以保持机器 Id。但直接按机器 Id 对比实例列表的差异，并不是最优匹配。如果是不考虑初态，从空集群开始，通过装箱算法得到的终态，那么机器 Id 基本就没有参考意义了。
注意到，对同类型的机器，它们的状态差别仅取决于部署的实例。假如终态的一台大型机器，它的实例列表与初态另一台不同 Id 的大型机器的完全相同，那么不需要迁移实例，直接把机器 Id 交换一下就可以了。当然这种情况是很少的。更可能的情况是，初态与终态有两台机器的实例列表的交集比例很大，那么交换机器 Id 比生成迁移动作更方便。另外，如果两台机器的实例列表不同，但实例所属的应用相同，直接修改终态中的实例 Id 即可，不必生成迁移动作。更进一步，如果两个应用的资源使用模型是一样的，或者差别很小，可以将其作为一类，就可以合并更多的实例。这就是 “对齐” 的想法。对齐之后，肯定还有一些机器存在显著差异，需要迁移实例。
可能出现目标机器尚未释放资源，或有干扰冲突，导致无法迁移成功的情况。这种情况可以将无法迁移的实例先放到到空闲机器或其它机器，暂时腾挪一下，待下轮再迁回目标机器。
如果不执行二分图匹配，直接腾挪其实也是可以的，但要看运气了。

决赛的队伍中， **1st - 我就看看队**，**2nd - greydog** 和 **4th - SuperUncle** 都提到了先匹配，再迁移。**1st - 我就看看队** 还提到他们又用了局部搜索来求解二分图匹配的近似解。**3rd - rivulet队** 和 **6th - 地球漫步** 是启发式的腾挪迁移。上面提到，**5th - yxgy** 的方案直接输出每步迁移动作即可。
我们当时考虑到匹配比较复杂，才没有这样。两种方案最终的成本分数是差不多的。

我个人认为迁移这部分与实际情况是有一定差距的。感觉实际集群运行一段时间后，虽然会偏离最优状态，但应该差距不大。比赛为了考察在线部署算法，所以提供的初始部署状态比较差，导致在迁移上要花一些心思。
即便需要大范围迁移，感觉划分轮次也是没有必要的。初赛的赛题解读中提到，迁移的成本是比较高的，而且不同应用的迁移时间不同，难以给出明确的限制。另外，为了并发迁移，也没必要限制在同一轮次内。
考虑迁移成本，应该按效果对迁移动作排序，并限制总的次数。

# 4. 装箱

初赛时有未部署的实例，所以需要考虑用装箱算法产生初始解。决赛中 **4th - SuperUncle** 只使用装箱算法，就完成了在线应用的部署；**2nd - greydog** 在复赛中也使用装箱算法来产生初始解；因为复赛的初始状态所有实例都已经部署了，其它几支队伍都直接从初态开始局部搜索。

下面是 C# 实现的 First Fit 和 Best Fit 装箱算法。其中用到的辅助代码有：
+ `cpuUtilLimit(m)`，根据机器 m 的容量类型返回设置的 CPU 利用率上限常数，我们对大型和小型机器设置了不同的限值。
+ `m.CanPut(inst, cpuUtilLimit = 1.0)`，`Machine` 类的方法，返回类型为 `bool`，检查在指定的 `cpuUtilLimit` 下，待部署的 `inst` 是否满足资源和干扰约束
+ `m.TryPut(inst, cpuUtilLimit = 1.0, autoCheck = true)`，`Machine` 类的方法，返回类型为 `bool`，将 `inst` 添加到机器的已部署实例列表，并更新内部相关状态；如果无法部署，该方法返回 `false`。默认参数 `autoCheck` 决定是否调用 `CanPut()` 函数检查约束，传入 `false` 则忽略约束，强制部署实例。
+ `inst.Machine`，`Instance`类的字段，记录 `inst` 部署的机器，如果 `inst` 尚未部署，该值为 `null`。
  
`m => metric(inst, m)` 这样的形式是 C# 的匿名函数，可以不写变量的类型，由编译器自动推导。
`Func<Instance, Machine, double> metric` 是一个函数形参，表示 `metric` 是一个参数类型为 `Instance, Machine`，返回值类型为 `double` 的函数。`metric` 是由调用方提供的计算实例和机器部署指标的函数。

```CSharp
// 不论 inst 是否已经部署了，只要找到合适的机器，都会将其部署到新的目标机器上
// 但是不会把 inst 放到原来的机器上
public bool FirstFit(Instance inst, IEnumerable<Machine> machines) {
    return machines.Where(m => inst.Machine != m)
                   .Any(m => m.TryPut(inst, cpuUtilLimit(m)));
}

// 按 metric 函数计算的指标，将实例部署到机器列表中最优（metric 最小）的机器上
public bool BestFit(Instance inst, IEnumerable<Machine> machines, Func<Instance, Machine, double> metric) {
    // 因 metric 涉及 实例 和 所有机器（随部署而变化的状态），这里不缓存分数
    // 但 metric 可以实现自己的分数缓存策略
    var bestList = machines.AsParallel()
                           .Where(m => inst.Machine != m && m.CanPut(inst, cpuUtilLimit(m)))
                           .OrderBy(m => metric(inst, m))
                           .Take(1)
                           .ToList();

    return bestList.Count > 0  && bestList[0].TryPut(inst, autoCheck: false);
}
```

+ First Fit（FF）：从机器列表中找到第一个可以部署实例的机器。部署每个实例都要从头遍历机器列表，所以不能通过划分机器列表并发执行。可以想到将一些放 “满” 了的机器（剩余资源都不足以部署最小的实例）移出列表，减少不必要的判断。不过 FF 执行时间还是比较短的，不移除也可以接受
+ Best Fit（BF）：标准的 BF 是将实例部署到剩余资源与实例资源使用量最接近的机器上；还可以定义其它指标，所以这里使用了一个函数参数 `Func<Instance, Machine, double> metric`。

上面代码中， FF 和 BF 只部署了一个实例。对所有实例，将其按资源使用量从大到小降序排序后（Decrease），再依次部署，就是 FFD 和 BFD 算法。因为资源是 **多维** 的，需要将其转换为一个一维的指标来排序。（其实可以对多维的资源直接排序，联想一下 SQL 的 `order by` 语句）

各种贪心的装箱算法基本都可以表示为某种指标的 BF。
下面摘自 [EuroSys 2015 会议发表的 Google Borg 论文](https://ying-zhang.github.io/yi/2017/x-eurosys15-borg-cn/)：
> Borg 早期使用修改过的 E-PVM [4] 算法来评分。这个算法对异构的资源生成等效的成本值，放置任务的目标是使 **成本的变化量最小**。在实践中，E-PVM 会把负载分散到所有机器，为负载尖峰预留出资源 —— 这样的代价是增加了碎片，特别是对需要 大部分机器的大型任务 而言；我们有时称其为 **“最差匹配（Worst Fit）”**。
> 与之相反的是 **“最佳匹配”**，把机器上的任务塞的越满越好。这就 “空” 出一些没有用户作业的机器（它们仍运行存储服务），这样放置大型任务就比较直接了。但是，如果用户或 Borg 错误估计了资源需求，紧实的装箱会对此造成（性能上的）惩罚。这种策略不利于有突发负载的应用，而且对申请少量 CPU 的批处理作业特别不友好，这些作业申请少量 CPU 本来是为了更容易被调度执行，并抓住机会使用空闲资源：20% 的 non-prod 任务申请少于0.1个CPU核。
> 我们目前的评分模型是混合的，试图减少搁浅（Stranded）的资源（指一台机器因某些类型资源全部分配了，导致未能分配的其它类型资源）。对我们的负载而言，这个模型比 “最佳匹配” 提升了 3%-5% 的装箱效率（以[78]定义的方式评价）。

其中提到的 Worst Fit ，其实也是 BF 的变种，只要把指标变成相反数就是 WF 了。
E-PVM 算法，其目标是 **成本的变化量最小**，结合比赛，可以理解为定义指标 $$\Delta s_j = s_j' - s_j$$，是将某个实例部署到机器 $$j$$ **前后** 该机器的成本分数变化量。

## 4.1 优化
BF 为了找出指标最小的机器，需要对所有机器计算 `metric` 函数，因为限制指标只与实例和单个机器有关，所以可以把机器列表划分给多个线程 **并发** 计算指标，上面直接使用了 PLINQ 的`AsParallel()`函数。
除了并发，BF 的一个优化是 **使用堆（优先队列）保存指标排序**：注意到一般有多个实例属于同一个应用。实际上计算 `metric` 用到的是 **应用** 的资源使用模型。部署了一个实例后，只改变了目标机器的状态，其它机器的指标 **不需要重新计算和排序**，为了使 BF 函数比较通用，这里交给 `metric` 来实现缓存机制。
另外，`Where` 子句中的判断 `m.CanPut(inst, cpuUtilLimit(m)` 也是比较复杂的，可以令 `metric` 为不满足约束的机器设置一个很大的值，这样就可以把 `CanPut` 这个判断从 `Where` 移到 `OrderBy` 子句的 `metric`，**利用上缓存机制了**。
BF 的另一个优化是 **随机近似**：不是从所有机器中选出最优值，而是随机选出 $$k$$ 台可行机器，从中选择最优的一个。

## 4.2 降维
标准的 BF 中，物品和箱子都是一维的。比赛中，资源共有 200 维，是多维装箱，具体说，是向量多维装箱（Vector multidimensional bin-packing，VMBP）。
VMBP （图 b）与普通多维装箱（几何装箱，图 a）的区别可以通过下图解释。现实中，多维物品可以通过旋转交换不同的维度，而 VMBP 各维度是独立的，不能转换。实际上，VMBP 要比几何装箱更简单些。

<img src="/img/gsac18_vmbp.png" width="450">
图片来自 "Christensen, H. I., Khan, A., Pokutta, S., & Tetali, P. 2017. ***Approximation and online algorithms for multidimensional bin packing: A survey***. Computer Science Review, 24, 63-79."

比较容易想到的降维方法是对各维加权求和：$$\sum_{i=1} w_i \cdot r_i$$ ；权重可以是各维资源平均值的倒数：$$w_i= 1 / Avg(r_i) $$，这样可以均衡各维资源的影响。这个指标只与实例本身的资源使用模型有关，用来对实例排序。

下面的指标可以用来选择目标机器。
***[Heuristics for vector bin packing](https://www.microsoft.com/en-us/research/publication/heuristics-for-vector-bin-packing/)***. （Panigrahy, R., Talwar, K., Uyeda, L., & Wieder, U. 2011. Microsoft Research.）这篇文章提出了多个启发式降维方法。例如（记 $$Avail$$ 是机器上的可用剩余资源），
+ 点积 Dot Product：$$\sum_{i} w_i \cdot r_i \cdot Avail_i$$ ；SigComm 2014 的文章 **[Multi-resource Packing for Cluster Schedulers](https://www.cs.cmu.edu/~xia/resources/Documents/grandl_sigcomm14.pdf)** 提出的 Tetris 系统（Tetris，即俄罗斯方块）就采用了点积这种方法
+ 范数：$$\sum_{i} w_i || Avail_i -  r_i ||_L$$，$$L1$$范数是取绝对值，$$L2$$范数是平方，$$L∞$$范数是取向量元素的最大值

> 这篇文章还介绍了两个随机化方法，
> • [GRASP，Greedy randomized adaptive search（贪心随机自适应搜索）](https://en.wikipedia.org/wiki/Greedy_randomized_adaptive_search_procedure)：类似上面提到的 BF 随机化，这里是指从前 $$k$$ 台最优的机器中随机选择一台
> • 冒泡：以概率 $$(1-p)^k$$ 选择前第 $$k$$ 台最优的机器
>
> 此外，文章还指出了装箱算法的两个角度：前面提到的 FF 和 BF 都是 **实例选机器（Item Centric）**，还可以 **机器选实例（Bin Centric）**。因为都是近似的算法，尝试后才能知道那种方式更好。

## 4.3 MRP
因为装箱有很多近似算法，以及不同的降维指标，那种更好是没有定论的，需要结合具体物品的分布规律，试验尝试。
***Vector bin packing with heterogeneous bins: application to the machine reassignment problem***. （[早期版本全文](https://hal.archives-ouvertes.fr/hal-00868016)）Gabay, M., & Zaourar, S. 2016. Annals of Operations Research, 242(1), 161-194. 是关于 2012 年 Google 与 ROADEF，EURO 合办的 [机器重分配问题挑战赛（Machine reassignment problem - the ROADEF-EURO challenge, MRP）](https://hal.archives-ouvertes.fr/hal-01366520)的一篇文章，对 MRP 比赛数据比较了多种装箱策略。

> MRP 挑战赛与这次阿里的 GSAC 有一些相同点，不过 MRP 的资源模型不同，约束比较复杂。Springer 有这次比赛算法介绍文章的专刊：https://link.springer.com/journal/10479/242/1，多是采用了局部搜索算法。
> 来自 **华中科技大学** 的一支队伍获得了比赛的第 15 名，他们的算法以 **[求解大规模云计算负载均衡问题的局部搜索算法](http://engine.scichina.com/publisher/scp/journal/SSI/45/5/10.1360/112013-143)** 为题（中文）发表在 2015年第5期 的 中国科学：信息科学 期刊。

## 4.4 SuperUncle， greydog
前面提到 **4th - SuperUncle** 只使用了装箱算法部署在线应用。由于没有看到代码，我尝试参考答辩视频理解他的思路。
他使用的指标是资源均匀程度的变化量。这个指标关注的是 **不同维度资源之间的平衡**。
首先，我们需要通过权重处理不同维度资源 $$r_i$$ 绝对值的差异，按上面提到的方式，选择各维资源平均值的倒数作为权重：$$w_i= 1 / Avg(r_i) $$ 。
加权后的各维资源平均值为：$$\bar r = \sum_{i=1}^{D} w_i \cdot r_i / D$$ （$$D = 200$$ 是资源维度，也可以考虑部分维度的资源，如 CPU，内存 和 硬盘）。
衡量均匀程度常用的是方差， $$\mathrm{Var} = \sum_{i=1}^{D} (w_i \cdot r_i - \bar r)^2 / D$$ ；也可以用绝对值代替平方，$$\sum_{i=1}^{D} |w_i \cdot r_i - \bar r| / D$$ 。
部署实例时，选择方差的 **变化量** 最小的机器。

**2nd - greydog** 在复赛中也使用装箱算法来产生初始解。由于没有看到代码，也是参考答辩视频。
他部署在线应用时，采用了 **机器选实例（Bin Centric）** 的方式。选择实例，使机器的 CPU 利用率最接近所有实例总的 CPU 利用率曲线。
所有实例总的 CPU 利用率曲线就是上面估算分数下界的 Python 代码中的 Cpu 列表（不需要舍入）除以集群的 CPU 总量，是固定的。
可以用差值的平方和或绝对值之和来衡量两个曲线的差异，即 $$\sum_{t=1}^{T} (c_{t,j} - C_t)^2$$ 或 $$\sum_{t=1}^{T} |c_{t,j} - C_t|$$ ，
其中 $$T=98$$，是分时曲线的数据点个数；$$c_{t,j}$$ 是机器 $$j$$ 在 $$t$$ 时刻的 CPU 利用率。

# 5. 作业

## 5.1 启动时间
离线作业与在线应用混合部署的主要目标是 **错峰填谷** 。如何选择作业的启动时间，使全部作业分散到资源使用低谷，是离线作业调度的重要问题。
一种方法是限制 CPU 利用率，来搜索作业合适的启动时间。这种方法应该先部署总执行时间比较长的作业。就是先放西瓜，再放芝麻。因为短的作业比较容易找到执行时段。

另一种是 **2nd - greydog** 的方法，他仍然是用所有实例总的 CPU 使用量曲线作为参照，不必考虑每台机器上在线应用的部署情况，就确定了作业的启动时刻。
首先按总执行时间对作业降序排序，然后依次确定每个作业的启动时刻：
对作业 $$k+1$$，它之前的作业已经确定了启动时刻；
当前集群的 CPU 总使用量包括：在线应用总的 CPU 使用量 $$\mathrm{CPU}_{App}$$ ，以及作业 $$1 - k$$ 的 CPU 使用量之和 $$\sum_{i=1}^{k} cpu_i $$：
$$\mathrm{CPU} = \mathrm{CPU}_{App} + \sum_{i=1}^{k} cpu_i $$
> 注意，总使用量 $$\mathrm{CPU}$$ 是有 1470 个数据点的分时曲线。

部署作业 $$k+1$$ 后的总使用量是 $$\mathrm{CPU}' = \mathrm{CPU} + cpu_{k+1}$$ 。作业 $$k+1$$ 的启动时刻是令 $$\mathrm{CPU}'$$ 的 **方差最小的时刻**。也就是说，尽量填平分时曲线。

**4th - SuperUncle** 的思路与 **2nd - greydog** 类似，也是考虑 CPU 均匀度来确定启动时间，但他是以 **任务** 为粒度的。

## 5.2 批次，堆
因为作业的实例很多，我们的实现在同一台机器上尽可能多分配同一任务的实例（称为批次，Batch）。不过决赛的队伍大部分都是单独部署每个实例，有的队伍没有明确。
部署同一个任务的实例时，涉及的计算是相同的（比如选择可用资源最多的机器），部署实例只影响当前选择的机器，其它机器的指标和排序不受影响，所以也可以 **使用堆保存分数排序**，减少不必要的计算。

## 5.3 局部搜索
**2nd - greydog** 和 **5th - yxgy** 在部署完作业后，还对其进行了局部搜索，包括尝试将实例迁移到其它机器，或者前后移动实例的执行时段。
我们的实现也有局部搜索，但发现效果不明显。

